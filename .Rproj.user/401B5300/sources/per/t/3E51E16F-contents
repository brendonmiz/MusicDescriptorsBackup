---
title             : "Cognitive Music Listening Space: A Multivariate Approach"
shorttitle        : "Music Descriptor Space"

author: 
  - name          : "Brendon Mizener"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "800 W. Campbell Rd., Richardson Tex"
    email         : "bmizener@utdallas.edu"
    role:         # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
      - Stimuli creation
      - Survey design & creation
      - Data collection & processing
      - Statistical analyses
      - Writing - Original draft preparation
  - name          : "Mathilde Vandenberghe"
    affiliation   : "2"
    role:
      - Original concept
      - Survey design & creation
  - name          : "Herv√© Abdi"
    affiliation   : "1"
    role:
      - Writing - Review & Editing
      - Statistical guidance
  - name          : "Sylvie Chollet"
    affiliation   : "2"
    role:
      - Original concept

affiliation:
  - id            : "1"
    institution   : "University of Texas at Dallas"
  - id            : "2"
    institution   : "YNCREA"

authornote: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

  Enter author note here.

abstract: |
  Participants with either French or American nationality responded to surveys featuring novel music stimuli and evaluated those musical excerpts using either adjectives or quantitative musical dimensions. We opted during the design phase of this study to permit lesser control of various parameters in order to reach a greater sample. We did not control how participants listened to the stimuli, but they were encouraged to use headphones or listen in a quiet listening environment. Participants were also able to complete the survey using a mobile device. Results were analyzed using correspondence analysis (CA), Hierarchical cluster analysis (HCA), Multiple Factor Analysis (MFA), and Partial Least Squares Correlation (PLSC). All except the HCA used Bootstrapping and Permutation testing for inferences. Significant differences were revealed in how French and American lay listeners responded to the excerpts. 
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["Music Descriptor Space.bib"]

floatsintext      : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
csl               : "apa7.csl"
classoption       : "man"
output            : 
  papaja::apa6_pdf: 
    latex_engine    : "xelatex"
header-includes   :
          - \usepackage{caption}

---

```{r setup, include = FALSE}
# Seed for random number generation
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message=FALSE, fig.align = "center",cache.extra = knitr::rand_seed)
set.seed(42)

papaja::r_refs("r-references.bib")
```

```{r analysis-preferences}
library("papaja")
suppressMessages(library(ExPosition))
suppressMessages(library(InPosition))
suppressMessages(library(MExPosition))
library(PTCA4CATA)
library(purrr)
library(plyr)
library(tidyverse)
library(readxl)
library(stringr)
library(stringi)
library(rlist)
library(wesanderson)
#library(kableExtra)
library(ggplotify)
library(gridExtra)
library(grid)
library(abind)

```

```{R graphPath}
powerpointFilename <- 'Music-Descriptor-Space.pptx'
path2pptx    <- './Analysis/'
name4Graphs  <- paste0(path2pptx,powerpointFilename)
title4Graphs <- 'Music Descriptor Space '
```


```{r citations, eval = FALSE, echo=FALSE, include=FALSE}




```
#top
  We have a data problem. This issue, especially in the United States, falls at the intersection of poverty, disability, and disparities in access to higher education for historically underserved communities. While a shift in data collection has long been warranted, world events over the past year have demonstrated to the scientific community the need for an expansion of common experimental paradigms. Specifically, the ability to collect data online or remotely has become a necessity. While online data collection won't solve all of the problems, as there is still a significant technology gap related to wealth, continued advances in technology have allowed for greater access to mobile technology [@Witte2013]. Continued improvements in the speed and capacity of mobile technology, coupled with continually improving online survey platforms, provide access to many populations that researchers may not have had access to before. Not just the general non-academic population, but specifically: racially and ethnically diverse populations, poorer populations, and other historically underserved populations - those with limited access to transportation, or who have a disability, or are immunocompromised.
  However, this shift in data collection paradigms necessitates a similar shift in analysis paradigms. Because experiments conducted in labs are subject to all of the controls that are possible under lab conditions, those data are cleaner that that collected using online surveys. Dirtier data means that most likely, some of the assumptions associated with traditional hypothesis testing and inferences are violated, and different methods of inference are necessary for analysis. One positive, however, is that the data for some studies will be collected under much more naturalistic settings. Studies like the present one, investigating music listening, will capture a much more ethologically valid listening experience. Additionally, the greater sample size that we can access using online surveys helps with some of these problems.  
  Multivariate analyses present a useful tool for dealing with 'dirty' data, that is, data with a smaller signal-to-noise ratio. With studies that are run online, using a univariate analysis isn't ideal, because any violations in the one target variable reduce the signal, and make it more difficult to either see results or draw conclusions. One solution is greater power, another is to increase the number of variables and change the analytical paradigm. Using a multivariate perspective helps the analysis. In a solution to a system in which there are 15-20 dimensions, greater noise in one or two of those dimensions is negligible because the multivariate solution evaluates the total variance in all of the dimensions, instead of the variance for each individual dimension separately. This makes the system and the solution more robust to violations and noise. This is especially the case when coupled with a large sample size to help improve overall power.  
  Here we present a case study using real data that addresses these questions. The initial motivation for this came from a study investigating cross modal sensory mapping between gustation perception, specifically beer, and music perception. As such, this study was designed to investigate whether a music cognitive listening space could be established using the experimental and analysis paradigm outlined below, to allow cross-modal comparison. Additional questions arise from the study itself: are there significant differences in how participants from different nationalities (and by extension musical cultures) perceive, or, more precisely, describe music? Are there parallels in how music is evaluated using music non-specific descriptors and music-specific qualities? 
  Music listening is a complex cognitive activity that involves many judgments per second. Listeners continuously evaluate incoming information and compare it with that which came before. These judgments involve many different dimensions of music related to both the technical and affective aspects of this acoustic medium. While these two aspects of music are theoretically distinct, in practice there is a great deal of interplay between the two. Listeners respond affectively to technical aspects of music, and composers use various musical and compositional techniques things to reflect the internal emotional states they want to express. Assessing the interplay between the two is quite a task, because it's difficult to isolate which musical mechanisms affect listeners in specific ways, to say nothing of the individual associations that participants bring to the table [@Kopacz2005]. 
  Research into the emotion of music, specifically, is a well-trod topic. See, for example, @Juslin2010. In the behavioral domain, a recent focus has been to ask participants to rate music with sliders [@Madsen1997; @Bigand2005], specifically asking the participants to evaluate 'arousal' and 'valence', features that were found very early to be defining elements of the first two dimensions of music affective perception [Osgood; Wedin]. This is useful, but limiting, as it provides fine-grained detail on  the level of arousal or valence a given stimulus provides, but does not qualify that information. Similarly, studies that ask participants to cluster stimuli depend on greater levels of interpolation from the researchers in determining affective impact. With advances in computational power and complexity, studies in the realms of computational neuroscience and electrical engineering, have aimed at classifying which physical characteristics of music correspond to which emotions in music [this needs a citation. find a review?]. This 'Music Emotion Retrieval' (MER) is an interesting computational exercise, but it ignores the semantics and associations of music that resonate with listeners. [cite the one about needing to consider individual associations or whatever it is]  
  Earlier studies in this domain evaluated how various technical aspects of music correspond to emotions for the purpose of induction, (see @BrunerII1990 for a summary) but the musical characteristics listed and they way they were investigated don't fully capture the dimensionality that composers consider when writing music. Also, many of the studies that take this perspective impose strict limitations on how the stimuli vary, which is useful for illuminating very specific effects of a single musical element or characteristic, but makes it impossible to evaluate interactions between any musical variables. Assessing the interplay between the technical aspects of music and descriptive/affective requires a fine - grained approach that is able to evaluate the correlations and covariates between many dimensions of music simultaneously.
  In terms of analysis, multidimensional scaling (MDS) was introduced fairly early in the field of music cognition as a means of evaluating the perceptual space around musical excerpts [@Wedin1969; @Wedin1972]. Studies in this vein have continued to date, including examples like @Droit-Volet2013 or @Roda2014, which continue to provide evidence supporting the existence of the valence-arousal plane. @Roda2014 specifically investigates what the dimensions beyond valence and arousal may be. However, these studies and their analyses have been limited in their attempts at analyzing and visualizing the factor space of their stimuli. These and others plot the stimuli in a factor space, using the valence-arousal plane as *a priori* defined axes. The use of the *a priori* defined axes is not per se a negative aspect of this, but the fact that these analyses are unable to evaluate both the music and semantic dimensions simultaneously. It's difficult therefore to evaluate the semantic and holistic music cognitive/emotional sensory space. Additionally, although it is a useful tool for evaluating this kind of data, it isn't the only tool, and we present some more possible analytical techniques below.  

## Present questions & methods of analysis
  In this study, we attempt to address three specific issues with the field as a whole: mode of investigation, sample & size, and analysis. The basic question was simple: how do French and American participants describe music? Our investigative paradigm, along with sample and size are addressed in the methods section below, but we felt it may be useful to provide a quick overview of the analytical techniques for readers who may be unfamiliar.  
  
### Data Collection
  While not invented by @Katz1933, that study provides an early example of the use of the Check-All-That-Apply (CATA) investigative paradigm in the psychological sciences. As a method it's not terribly common in that domain any more, but it has been and continues to be used widely in sensory evaluation to "obtain rapid product profiles" [@Meyners2014] from participants. In this method, participants are asked to select from a list any and all items that describe a given prompt. This allows researchers to collect a lot of data about a given stimulus without placing an overbearing demand on the participants. In our study, one of our surveys asked participants to select any and all adjectives that they felt described a musical stimulus. A single stimulus may be described by multiple adjectives, so selecting only one 'correct' answer is not necessary. Similarly, the adjectives that may only partially describe the stimulus, or do so tangentially, are likely to be selected by fewer participants, and adjectives that more completely describe the stimulus will be selected by more participants. Thus we have a data collection paradigm that allows for a gradient across the adjectives and stimuli that is robust to violations, either intentional or not. A more complete treatment of the value of such a data collection mechanism, including assessments in which there is a 'correct' answer, is found in @Coombs1956.  

### Data processing
  Raw data were cleaned and processed in Excel and R. This included translating all French responses to English for ease of analysis. Data were cleaned and transformed into a pseudo contingency table for each participant, with the stimuli, as observations, on the rows and the responses as variables on the columns. Because we are using the CATA technique, a one (1) at the intersection of each row or column indicates that the participant selected that adjective or musical quality for that stimulus. A zero means that they did not. These individual tables were all compiled into into two 'bricks', or three-dimensional arrays of data with the same structure for the rows and columns, and the participants on the third dimension, which we will refer to as 'pages' here. Each array was then summed across pages into a single, two dimensional, summary pseudo-contingency table, so that any given cell contained the total number of times a participant selected a given adjective or quality for a given stimulus. These tables were then analysed individually using correspondence analyses, and together using a Partial Least Squares Correlation (PLSC) (see @Abdi2013a) to see what information was shared between the two tables.
  Since we did not use *a priori* grouping variables for the excerpts or adjectives, the summed tables were evaluated using hierarchical cluster analyses to see what groupings arose during evaluation. Hierarchical cluster analyses, included in supplementary materials, captured groupings of the excerpts when rated by the adjectives and when rated on musical qualities. We also used k-means to evaluate groupings of the adjectives themselves. We attempted other cluster analyses for the adjectives, but k-means provided the most intuitive interpretation. The musical qualities were grouped by quality (e.g., levels of tempo, types of genre). 
  In order to analyze differences between participants, the three-dimensional arrays were also transformed into symmetric distance matrices; square, symmetrical matrices with participants on both rows and columns, in which each cell represents the distance (the amount of difference) between those two participants. We used that matrix to analyze differences between the participants using grouping variables extracted from the demographics portions of the surveys as factors. Additionally, once we found significant differences between the French and American participants in the results of the adjectives survey, we ran an unplanned, post-hoc Multiple Factor Analysis (MFA) using separate contingency tables for the French and American participants. 

### Correspondence Analysis
  The primary analysis used on the data collected in the surveys is Correspondence Analysis (CA). CA has many names, and has been 'discovered' many times by many people. There are a number of excellent references that illustrate the calculative [@Greenacre1984] and graphical or geometrical [@Benzecri1973]. CA is similar to Principal Components Analysis (PCA), except that it allows for the analysis of qualitative data. Data for a CA is organized in a contingency table or a pseudo contingency table. Whereas a contingency table would be when a participant selects only one option from a list for each stimulus, resulting in a table for each participant with one and only one one (1) per row, a pseudo contingency table has as many ones as items selected for a given stimulus. Because we use a CATA paradigm for the adjective survey, we use the latter. Because the value in any given cell represents the relationship between the observation and the variable symmetrically, this technique allows for a biplot of both rows and columns in a single factor space. In addition to factor plots, we used permutation tests and bootstrapping for statistical inferences. Extensions of this technique, including Multiple Correspondence Analysis (MCA) and Discriminant Correspondence Analysis (DiCA), can be used to evaluate tables with binned levels of a given variable (age, for example), or when the goal is to categorize and classify the observations or any new observations. DiCA is therefore essentially a 'machine learning' technique.
  Additionally, this technique was chosen because it allows for biplots; the simultaneous display of row and column factor scores in the same factor space. This allows us to visualize the excerpts and the descriptors in the same space, which provides a clear, quick, visual reference for what excerpts or musical pieces fall in to what quadrant or area of the cognitive space. 

### Multiple Factor Analysis

  MFA analyzes and visualizes multiple tables or groups of variables simultaneously, and allows for the disambiguation of the various contributions of either a population or a set of variables in a plot. The observations must all be the same for MFA, but analysis can either evaluate the entire population, with the variables grouped in ways that are useful or valuable to isolate, or with separate populations, using all the same variables for both groups. The number of tables (i.e., populations or groups of variables) you choose to analyse is limited by what makes sense, either mathematically in your planned analyses or visually in the partial factor scores plots. In any case, the visualization output for this plot provides the researcher with factor scores of the observations overall, and partial factor scores showing how each of the tables contributed to each observation; where each individual weighted table would fall in the factor space relative to the other/s. Because the tables for this analysis are weighted according to their overall inertia, with larger tables being weighted less than smaller tables, this is a very useful technique when dealing with unbalanced groups. In a PCA, for example, greater values are given greater importance, but MFA is more like equal rights.
  

### Partial Least Squares Correlation

  Partial Least Squares Correlation (PLSC) analyzes two data tables that have the same information either on the observations (rows) or variables (columns). The PLSC extracts the covariance between two tables in the form of *latent variables*. This technique is commonly used in neuroimaging studies to evaluate correlations between matrices of imaging data and of behavioral or task data [@Krishnan2011]. In our context, the PLSC extracts the information that is shared between the adjectives ratings and the musical dimensions ratings. The stimuli are on the observations (rows) for both data tables. Additionally, the contributions and loadings will show us which variables are responsible for creating or defining the primary axes of similarity between the two data sets. There are some criticisms of this technique that argue that it is overpowered, that it can 'find' spurious correlations, and to that end we would simply suggest caution when interpreting PLSC results.   
  
### Inference Methods
  Because the methods outlined above are not specifically inferential methods, and do not inherently allow for hypothesis testing, we need to also apply methods that help with that. In the cases below we use permutation testing [cite] and bootstrapping [cite]. Permutation testing shuffles the data and recomputes the eigenvalues. Because eigenvalues are also an indication of how much variance is extracted by each dimension, random data should give us smaller eigenvalues. Therefore, if the observed eigenvalues are larger than a certain threshold, we can infer that the data we collected do, in fact, represent something real or important. Importantly, this is determined by the number of iterations that we permute, we can only infer to that degree. If we want to infer to the standard alpha level of .05, then we would need to run at least 100 permutations, and hope that the observed result was one of the largest five values. 
  Bootstrapping is essentially resampling with replacement. We use this technique for two of the measures: the first  to resample the factor scores to establish a confidence interval around the mean of the groups, the other is to resample with a focus on the loadings, to see which of the observations and variables load consistently on the dimensions we're interpreting. Both give us an idea of the consistency of the data, and can once again, based on the number of iterations, give us an idea of the statistical significance of mean differences.

# Methods

## Participants
  Participants (N = 604) were recruited similarly for both Experiments 1 and 2, and thus are discussed simultaneously here. Participants for this study were recruited in multiple ways. The participants in the United States (n = 292) were recruited using the traditional method of offering experimental participation credit, and also via social media. French participants (n = 312) were recruited by word of mouth, email, and social media. The only restrictions on participation were that the participant must have self-reported normal hearing. We recognize that although we suggest that data collected in this way have a much greater hypothetical reach, the data here represent a) a convenience sample, b) that is limited to participants that have access to the internet. Both of these specific limitations could be remedied when designing and implementing future research.  
  The population we recruited was different for the two experiments. For Experiment 1, we specifically sought out highly trained musicians (n = 84) with ten years or more of music training. We recruited this population for two reasons: firstly, as a validation step, to ascertain whether the stimuli truly reflected the composer's intent. Secondly, we had the goal of evaluating how the musical qualities of the stimuli, as evaluated by the trained participants, correlated with the adjectives selected by those who participated in the adjectives survey. Participants were recruited for Experiment 2 (n = 520) without regard to level of music training.  
  Of the responses to Experiment 1, 51 were removed to incomplete data (nf = 45, nA = 6), leaving a total of 33 for the analysis. Of the responses to experiment 2, 160 were removed for not completing the survey (nF = 140, nA = 20), leaving a total of 360. Of the responses to the survey administered in the US, participants were excluded from analysis if they indicated a nationality other than American. "Asian-American", for example, was included, but "Ghanian" was not. This left a total of 279 survey responses for experiment 1 and 312 for analysis across both experiments. 
  All recruitment measures were approved by the UT Dallas IRB.
  
## Material

### Stimuli
  All stimuli were original, novel musical excerpts, in various western styles, composed for this study. They were designed to evaluate a number of musical dimensions and control for others (e.g., timbre). The stimuli were all string quartets, in order to control for the confounding factor that different instruments are fundamentally described in different ways. All stimuli were between 27s and 40s long, with an average length of 32.4s. The intent was to have all stimuli be around 30s long while preserving musical integrity. All stimuli were composed using finale version 25.5.0.290 [cite finale] between April 13 and June 18, 2020. Stimuli were recorded as wav files directly from finale using the human playback engine and embedded into each question in qualtrics in that format.

### Surveys
  There were two separate surveys presented to participants. The survey used in Experiment 1 (hereafter: Qualities Survey/QS) evaluated the musical stimuli on concrete musical qualities like meter and genre. The survey used in Experiment 2 (hereafter: Adjectives Survey/AS) asked participants to evaluate the stimuli using adjectives using the CATA paradigm. Both surveys also captured participants' demographic data, including age, gender, nationality, occupation, and musical experience.  
  The qualities assessed in the QS were selected from standard music-theoretical descriptors of western music. For example, when rating the excerpts on tempo, participants were asked to rate the excerpt using the scale *Very Slow*, *Slow*, *Moderately Slow*, *Moderate*, *Moderately Fast*, *Fast*, and *Very Fast*. The full list of musical qualities and associated levels is in [supplementary materials?]. The words for the AS were selected using @Wallmark2019 as a guide and in consult with a French professional musician. Some words were initially selected in French and some in English. In all cases, words were selected for which there was a clear French (vis-a-vis English) translation. The words and their translations are listed in [supplementary materials?]. 
  
## Procedure
  Participants were provided with a link to either the AS or the QS. Both surveys were administered using Qualtrics. After standard informed consent, participants listened to 15 excerpts and answered questions. Demographic survey questions followed the experimental task. Participants were instructed to listen to the excerpts presented either using headphones or in a quiet listening environment, but that was not strictly controlled, nor was it part of the survey. Participants in Experiment 1 answered 10 questions per excerpt, rating the excerpts using the qualities and scales provided. Participants in Experiment 2 answered a single question per excerpt, in which they selected any and all adjectives that they felt described the excerpt.  
  
# Results
## Experiment 1: Musical Qualities Survey

```{r importQualdata}

load("catadatamusdim.RData")
musdimdata <- catadata.list$contingency
numberofdims <- catadata.list$numberofdims
thebrick <- catadata.list$thebrick

rows2drop <- c(6,14) 

musdimdata.no6 <- musdimdata[-rows2drop,]
thebrick.no6 <- thebrick[-rows2drop,,]
```

```{r Q.parts}

# reorder some of the columns in the french experts dataset, 
# taking only the ones we want to analyse for now
fr.ex.data <- catadata.list$french.expert.data[c(1:3,6,7,9:12),c(1,4,5,6,7)]
colnames(fr.ex.data) <- c("age", "gen", "nat", "tr_yrs", "tr_type")
fr.ex.data$gen[which(fr.ex.data$gen == "Homme")] <- "M"
fr.ex.data$gen[which(fr.ex.data$gen == "Femme")] <- "F"
fr.ex.data$nat <- "FR"
fr.ex.data$tr_type[which(fr.ex.data$tr_type == "Instrumentale")] <- "Inst"
fr.ex.data$tr_type[which(fr.ex.data$tr_type == "Vocale")] <- "Voc"

am.ex.data <- catadata.list$expert.data[,c(1:3,6,7)]
colnames(am.ex.data) <- colnames(fr.ex.data)
am.ex.data$nat <- "AM"
am.ex.data$gen[which(am.ex.data$gen == "Male")] <- "M"
am.ex.data$gen[which(am.ex.data$gen == "Female")] <- "F"
am.ex.data$tr_type[which(am.ex.data$tr_type == "Instrumental")] <- "Inst"
am.ex.data$tr_type[which(am.ex.data$tr_type == "Vocal")] <- "Voc"

# Bind it all together
ex.data <- rbind(am.ex.data, fr.ex.data)

bygender <- as.factor(ex.data$gen)
bynationality <- as.factor(ex.data$nat)

```

```{r Q.ca, cache = T, message=FALSE, warning=FALSE, include = FALSE}

dimcares.inf <- epCA.inference.battery(musdimdata.no6, 
                 masses= NULL, weights= NULL, 
                 hellinger = FALSE, symmetric = TRUE, 
                 graphs =FALSE, test.iters = 1000)

# Factor Scores
FIsym  <- dimcares.inf$Fixed.Data$ExPosition.Data$fi
#FIasym <- RenormFi$G_A
FJs    <- dimcares.inf$Fixed.Data$ExPosition.Data$fj
CA.Q.Eigs <- dimcares.inf$Fixed.Data$ExPosition.Data$eigs
CA.Q.pEig <- dimcares.inf$Inference.Data$components$eigs.perm
```

```{r someQcolors}
# Participant colors:
col4M <- wes_palettes$Rushmore1[3]
col4F <- wes_palettes$Rushmore1[5]
col4FR <- wes_palettes$Darjeeling1[1]
col4AM <- wes_palettes$Darjeeling2[2]
# 
col4byG <- as.character(bygender)
col4byG[col4byG == "F"] <- col4F
col4byG[col4byG == "M"] <- col4M

col4byN <- as.character(bynationality)
col4byN[col4byN == "FR"] <- col4FR
col4byN[col4byN == "AM"] <- col4AM

# To account for the fact that we removed some rows above:
numberofdims[c(1,7,8,9,10)] <- c(8,7,3,4,6)
numberofdims <- numberofdims[-11]

col4cols <- wes_palette("FantasticFox1", 
                        length(numberofdims), type = "continuous")
col4cols <- rep(col4cols, numberofdims)

```

```{r bootQCA, cache=TRUE}

bootCA <- Boot4PTCA(ZeDataCube = thebrick.no6,
           fi = FIsym,
           fj = FJs,
           eigs = CA.Q.Eigs,
           nf2keep = 3,
           nBootIter = 500)
# Compute Bootstrapped ratios
bootRatios.I <- PTCA4CATA::boot.ratio.test(bootCA$RowsBoot,
                                            critical.value = 2)
bootRatios.J <- PTCA4CATA::boot.ratio.test(bootCA$ColumnsBoot,
                                              critical.value = 2)
# Probabilities 
probBR.I  <- bootRatios.I$prob.boot.ratios
probBR.J  <- bootRatios.J$prob.boot.ratios
```

```{r ca4Judges.Q}
# We have a problem here because most matrices
#  have lines with zeros. A symmetric difference matrix 
#  would do better than an RV or a 
#  chi2 distance so we use createSymDist4PTCA

Cmat.Q <- createSymDist4PTCA(thebrick)$CrossProduct

# Calculate the eigenvalues and the percentage of variance extracted (tau)
eigenCmat.Q <- eigen(Cmat.Q, symmetric = TRUE)
eig4Cmat.Q <-  eigenCmat.Q$values
tau4Cmat.Q <- round( (100*eig4Cmat.Q) / sum(eig4Cmat.Q))

# Calculate factor scores for the first three dimensions
nk       <- 3
F4Cmat.Q   <- eigenCmat.Q$vectors[,1:nk] %*% diag(eig4Cmat.Q[1:nk]^(1/2))

# Prep for plotting
Shortnames4Participants.Q <-  dimnames(thebrick[[3]])
rownames(F4Cmat.Q) <- Shortnames4Participants.Q

# Make labels
labels4RV.Q <- createxyLabels.gen(1,2,lambda = eig4Cmat.Q, tau = tau4Cmat.Q)
```

### Participants
  The scree plot in \@ref(fig:screeRV) shows the eigenvalues for the distance analysis between musical experts. The usual guideline of analyzing only dimensions with eigenvalues greater than one seems prohibitive here, as all dimensions except the last have $\lambda$ > 1. For the purposes of this experiment, we've opted to focus on the first two dimensions, with $\lambda$ = `r round(eig4Cmat.Q[1], 3)` and $\lambda$ = `r round(eig4Cmat.Q[2], 3)`, respectively. This scree plot suggests that each of the participants is contributing similarly to the dimensionality of this analysis. To evalute this, we ran a Multidimensional Scaling (MDS) analysis on a double-centered cross product symmetric distance matrix calculated from the pages of the brick. This analysis revealed no significant difference between the experts based on any of the grouping variables used. The factor plots in \@ref(fig:judgesplot.Q) show how the means of the factor scores, grouped by either nationality or gender, show the means clustered on top of one another, right at the origin. The overlapping ellipses are the confidence intervals for the means.

```{r screeRV, fig.height = 4, fig.width = 8, fig.align='center'}
# Scree plot with significance
ScreeInf <- PlotScree(ev = eig4Cmat.Q,
                      max.ev = NULL, alpha = 0.05,
                      col.ns = "#006D2C", plotKaiser = TRUE,
                      title = "Participants Distance Analysis, Musical Qualities Survey: \nExplained Variance per Dimension")
a000.00.screeRV <-  recordPlot()
```


```{r judgesplot.Q, fig.height = 6, out.width = '50%'}

BaseMap.Nationality <- createFactorMap(X = F4Cmat.Q ,
                              axis1 = 1, axis2 = 2,
                              display.points = TRUE,
                              col.points = col4byN,
                              pch = 19, cex = 2.5, 
                              title = "Colored according to Nationality",
                              display.labels = TRUE,
                              col.labels = col4byN,
                              text.cex = 4, font.face = "bold",
                              font.family = "sans",
                              col.axes = "darkorchid",
                              alpha.axes = 0.2,
                              width.axes = 1.1,
                              col.background = adjustcolor("lavender",
                                                       alpha.f = 0.2),
                              force = 1, segment.size = 3)

BaseMap.Gender <- createFactorMap(X = F4Cmat.Q ,
                              axis1 = 1, axis2 = 2,
                              display.points = TRUE,
                              col.points = col4byG,
                              pch = 19, cex = 2.5,
                              title = "Colored according to Gender",
                              display.labels = TRUE,
                              col.labels = col4byG,
                              text.cex = 4, font.face = "bold",
                              font.family = "sans",
                              col.axes = "darkorchid",
                              alpha.axes = 0.2,
                              width.axes = 1.1,
                              col.background = adjustcolor("lavender",
                                                       alpha.f = 0.2),
                              force = 1, segment.size = 3)

gendermeans <- getMeans(F4Cmat.Q, bygender)
nationmeans <- getMeans(F4Cmat.Q, bynationality)

BootCube.N <- PTCA4CATA::Boot4Mean(F4Cmat.Q, design = bynationality,
                      niter = 100,
                      suppressProgressBar = TRUE)
dimnames(BootCube.N$BootCube)[[2]] <- paste0('Dimension ',
                                             1: dim(BootCube.N$BootCube)[[2]])

BootCube.G <- PTCA4CATA::Boot4Mean(F4Cmat.Q, design = bygender,
                      niter = 100,
                      suppressProgressBar = TRUE)
dimnames(BootCube.G$BootCube)[[2]] <- paste0('Dimension ',
                                             1: dim(BootCube.G$BootCube)[[2]])

n.ellipse <- MakeCIEllipses(BootCube.N$BootCube[,1:2,], 
                            names.of.factors = c("Dimension 1","Dimension 2"),
                            col = c(col4AM, col4FR))
g.ellipse <- MakeCIEllipses(BootCube.G$BootCube[,1:2,], 
                            names.of.factors = c("Dimension 1","Dimension 2"),
                            col = c(col4M, col4F))

n.symdist.means <- createFactorMap(nationmeans,
                              axis1 = 1, axis2 = 2, 
                              title = "Colored according to Nationality",
                              col.points =  c(col4AM, col4FR),
                              alpha.points = 1, # no transparency
                              constraints = BaseMap.Nationality$constraints,
                              display.points = TRUE,
                              pch = 19, cex = 5,
                              display.labels = TRUE,
                              col.labels = c(col4AM, col4FR), 
                              text.cex = 4,font.face = "bold",
                              font.family = "sans", col.axes = "darkorchid", 
                              alpha.axes = 0.2, width.axes = 1.1, 
                              col.background = adjustcolor("lavender", alpha.f = 0.2), 
                              force = 1, segment.size = 0)

g.symdist.means <- createFactorMap(gendermeans,
                              axis1 = 1, axis2 = 2, 
                              title = "Colored according to Gender",
                              col.points =  c(col4M, col4F),
                              alpha.points = 1, # no transparency
                              constraints = BaseMap.Gender$constraints,
                              display.points = TRUE,
                              pch = 19, cex = 5,
                              display.labels = TRUE,
                              col.labels = c(col4M, col4F), 
                              text.cex = 4,font.face = "bold",
                              font.family = "sans", col.axes = "darkorchid", 
                              alpha.axes = 0.2, width.axes = 1.1, 
                              col.background = adjustcolor("lavender", alpha.f = 0.2), 
                              force = 1, segment.size = 0)

a.01.map4part <- BaseMap.Nationality$zeMap_background + labels4RV.Q +
                   n.symdist.means$zeMap_dots + n.ellipse +
                    BaseMap.Nationality$zeMap_dots + n.symdist.means$zeMap_text
                    

a.02.map4part <- BaseMap.Gender$zeMap_background + labels4RV.Q +
                  g.symdist.means$zeMap_dots + g.ellipse +
                    BaseMap.Gender$zeMap_dots + g.symdist.means$zeMap_text

grid.arrange(as.grob(a.01.map4part), 
             as.grob(a.02.map4part), ncol = 2,
             top = textGrob("Factor Scores for Expert Ratings", 
                            gp = gpar(fontsize = 18, font = 3)))


```



### Excerpts

```{r getQeigs}
dim1eigperc <- round(100*(dimcares.inf$Fixed.Data$ExPosition.Data$eigs[1]/sum(dimcares.inf$Fixed.Data$ExPosition.Data$eigs)), 2)

dim2eigperc <- round(100*(dimcares.inf$Fixed.Data$ExPosition.Data$eigs[2]/sum(dimcares.inf$Fixed.Data$ExPosition.Data$eigs)), 2)

dim3eigperc <- round(100*(dimcares.inf$Fixed.Data$ExPosition.Data$eigs[3]/sum(dimcares.inf$Fixed.Data$ExPosition.Data$eigs)), 2)
```

The scree plot for the analysis of the musical quality ratings survey, \@ref(fig:scree4excerptsq), shows the high dimensionality of this space, with the first three dimensions extracting a total of `r dim1eigperc`%, `r dim2eigperc`% and `r dim3eigperc`% respectively, totaling only `r sum(dim1eigperc, dim2eigperc, dim3eigperc)`% of the variance. It isn't until we get to the 11th dimension that we see >80% of the variance explained. However, given that the assumption in an analysis like this is that the sample is random, it's important to take these numbers with a grain of salt. Music itself is not random, and in a single excerpt of music of the type that was presented in this study, repetition is common, and some musical qualities are inextricably linked, for example some stylistic elements with genre. 

```{r scree4excerptsq}
mus.scree <- PlotScree(dimcares.inf$Fixed.Data$ExPosition.Data$eigs, 
                       dimcares.inf$Inference.Data$components$p.vals, 
                       plotKaiser = T, color4Kaiser = "red"
                                              ) 

mus.00.scree <- recordPlot()

```
  
  Graphing the variable loadings (see \@ref(fig:contributionsQ)) of the musical qualities shows which ones contribute the most to the first two dimensions. Because of how CA is calculated, we know that the excerpts that load on the same dimension and direction as the musical qualities are the excerpts that are most associated with those qualities. The contributions shown here are only those that contribute significantly to the first two dimensions.
  There are some obvious groups of variables, especially tempo and articulation in the first dimension, with fewer contributions from the dynamics group. The tempo variables, which are a continuum, load from high (tempo.F6 and tempo.F7) in the positive direction to low (tempo.F2 and tempo.F1) in the negative direction. Other contributions are one-off: major harmony, triple meter, classical genre, undulating contour, and disjunct motion. The excerpts that load positively, and are therefore associated with the qualities that load in the positive direction, are all from group 2: Excerpts 4, 13, 23, and 26. The ones that load in the negative direction are from mostly from group 4: Excerpts 7, 10, 24, and 27, with one from group 3, Excerpt 3.  
  The second dimension seems to dominated by a few groups: harmony, meter, genre, dynamics. The one-offs are slow tempo, ascending contour, and "no melody". The excerpts that load significantly on this dimension are from all four groups. In the positive direction, it's Excerpts 7, 12, 15, and 27 from Group 4, and Excerpt 19 from Group 1. In the negative direction it's Excerpts 2, 3, 11, and 17. All are from group 3 except for Excerpt 2, which is from Group 2. For a full enumeration of contributions, loadings, and boostrap ratios, see table [insert table number, also, make up table.] in the supplementary materials.

```{r justsomecontsQ}

load("excerptsdesign.RData")

col4exgrp <- excerptsdesign$ex.design$col4exgrp
ex.cols <- excerptsdesign$ex.design$ex.cols

signed.ctrI <- dimcares.inf$Fixed.Data$ExPosition.Data$ci * sign(FIsym)
signed.ctrJ <- dimcares.inf$Fixed.Data$ExPosition.Data$cj * sign(FJs)

CIlist.dim <- vector(mode = "list", length = 3)
CJlist.dim <- vector(mode = "list", length= 3)

names(CIlist.dim) <- c("Dim1", "Dim2", "Dim3")
names(CJlist.dim) <- c("Dim1", "Dim2", "Dim3")

for (i in 1:3){
  CIlist.dim[[i]] <- signed.ctrI[which(abs(signed.ctrI[,i]) > 1/nrow(signed.ctrI)),i]
  CJlist.dim[[i]] <- signed.ctrJ[which(abs(signed.ctrJ[,i]) > 1/nrow(signed.ctrJ)),i]
}

col4barsQ <- vector(mode = "list", length = 6)
names(col4barsQ) <- c("IDim1", "JDim1", "IDim2", "JDim2", "IDim3", "JDim3")

nrows <- nrow(signed.ctrI)

```

```{r contributionsQ, fig.width=10}
# plot contributions of rows for component 1
ctrI.1 <- PrettyBarPlot2(CIlist.dim$Dim1,
                         threshold = 1 / NROW(signed.ctrI),
                         font.size = 3,
                         color4bar = col4exgrp[which(abs(signed.ctrI[,1]) > 1/nrow(signed.ctrI))] , # we need hex code
                         ylab = 'Contributions', #sortValues = TRUE,
                         ylim = c(1.2*min(signed.ctrI[,1]), 1.2*max(signed.ctrI[,1]))
) #+ ggtitle("Component 1", subtitle = 'Rows')

# plot contributions of columns for component 1
ctrJ.1 <- PrettyBarPlot2(CJlist.dim$Dim1,
                         threshold = 1 / NROW(signed.ctrJ),
                         font.size = 3,
                         color4bar = col4cols[which(abs(signed.ctrJ[,1]) > 1/nrow(signed.ctrJ))], # we need hex code
                         ylab = 'Contributions',
                         ylim = c(1.2*min(signed.ctrJ[,1]), 1.2*max(signed.ctrJ[,1]))
) #+ ggtitle("", subtitle = 'Columns')

# plot contributions of rows for component 2
ctrI.2 <- PrettyBarPlot2(CIlist.dim$Dim2,
                         threshold = 1 / NROW(signed.ctrI),
                         font.size = 3,
                         color4bar = col4exgrp[which(abs(signed.ctrI[,2]) > 1/nrow(signed.ctrI))] , # we need hex code
                         ylab = 'Contributions',
                         ylim = c(1.2*min(signed.ctrI[,2]), 1.2*max(signed.ctrI[,2]))
) #+ ggtitle("Component 2", subtitle = 'Rows')

# plot contributions of columns for component 2
ctrJ.2 <- PrettyBarPlot2(CJlist.dim$Dim2,
                         threshold = 1 / NROW(signed.ctrJ),
                         font.size = 3,
                         color4bar = col4cols[which(abs(signed.ctrJ[,2]) > 1/nrow(signed.ctrJ))], # we need hex code
                         ylab = 'Contributions',
                         ylim = c(1.2*min(signed.ctrJ[,2]), 1.2*max(signed.ctrJ[,2]))
)# + ggtitle("", subtitle = 'Columns')

# plot contributions of rows for component 2
ctrI.3 <- PrettyBarPlot2(CIlist.dim$Dim3,
                         threshold = 1 / NROW(signed.ctrI),
                         font.size = 3,
                         color4bar = col4exgrp[which(abs(signed.ctrI[,3]) > 1/nrow(signed.ctrI))] , # we need hex code
                         ylab = 'Contributions',
                         ylim = c(1.2*min(signed.ctrI[,3]), 1.2*max(signed.ctrI[,3]))
)# + ggtitle("Component 3", subtitle = 'Rows')

# plot contributions of columns for component 2
ctrJ.3 <- PrettyBarPlot2(CJlist.dim$Dim3,
                         threshold = 1 / NROW(signed.ctrJ),
                         font.size = 3,
                         color4bar = col4cols[which(abs(signed.ctrJ[,3]) > 1/nrow(signed.ctrJ))], # we need hex code
                         ylab = 'Contributions',
                         ylim = c(1.2*min(signed.ctrJ[,3]), 1.2*max(signed.ctrJ[,3]))
)# + ggtitle("", subtitle = 'Columns')

grid.arrange(
    as.grob(ctrI.1),as.grob(ctrJ.1),
    as.grob(ctrI.2),as.grob(ctrJ.2),
#    as.grob(ctrI.3),as.grob(ctrJ.3),
    ncol = 2,nrow = 2,
    top = textGrob("Contributions", gp = gpar(fontsize = 18, font = 3))
  )

Ctr.IJ <- recordPlot()

#1 - blue, 2 - red, 3 - green, 4 - yellow
```





### Discussion

  The graph depicted in \@ref(fig:factormapswsimplexQ) is a biplot depicting how excerpts and variables plot in the same space.  This biplot is possible because of the nature of correspondence analysis. Because the rows and columns of the contingency table X by definition have the same variance, the eigenvalues extracted from X are the same as X^T. Thus the axes on which the factor scores are plotted are the same for both the rows and the columns. However, interpretation requires some discernment. The distance between the excerpts can be interpreted directly as similarity, and the distance between the musical qualities can be interpreted directly as similarity, but the distance between a quality and an excerpt cannot. Instead, the angle between an excerpt and a quality is indicative of their correlation. An angle of 0 indicates a correlation of 1, an angle of 90 indicates a correlation of 0, and an angle of 180 indicates a correlation of -1.  
  Overall, this helps us to evaluate what contribute to the excerpt groupings. These first two dimensions suggest that the hierarchical cluster analysis *[see supplementary materials]* revealed groupings roughly according to genre. However, there are two notable outliers. Excerpts 6 and 14 are unique in that they are each the only representative of their respective genres. Excerpt 6 is minimalist, a la Steve Reich, and Excerpt 14 is jazzy. Preliminary versions of this analysis showed that they dominated the 2nd and 3rd dimensions, respectively (see supplementary materials for visualizations). In the plot below, they are included instead as supplementary projections, essentially 'out of sample' elements. Their placement on the plot below alludes to the fact that the dimensionality of this space may in fact be related to musical genre or family. Although they dominated the space when included in the sample, they are much closer to the barycenter of the plot when included as out of sample. Were they to fall exactly on the origin, that would suggest that they shared no information whatsoever with the other excerpts included in the analysis. The disparity between their placement on the graph below and their placement on the graphs in which they are included in the main sample suggests that they share some information, but there is still a large amount of information that is not accounted for in the factor space below.  
  One perceptual element that is revealed here is that tempo and dynamics seem to contribute, intensity-wise, similarly to the first dimension. This points to two specific things. Firstly, it highlights possible bias in the compositional process. The excerpts were not intentionally composed with those characteristics being similar in mind, but it's entirely possible that the high or low arousal levels of the various excerpts that participants respond to also drove some of the compositional process, and that turned up in the results. Secondly, it's possible that the level of arousal was conflated between various musical qualities. For example, given two excerpts of similar tempo, one may have been rated slightly faster if it was also louder, and the other slightly slower if it was quieter. Likewise, given excerpts of similar volume, a faster one may have been rated louder than a slower one. Perception of tempo is also affected by note rate, which is also tied to arousal. In two pieces played at the same tempo, the one with more notes per unit time is more likely to be judged faster than one with fewer. [citations for all of this]
  There are also a few musical elements revealed from the associations. The term staccato means short or light and separated, and the term legato means smooth and connected. The participants in this experiment didn't have access to the notation, so they would be judging the excerpts aurally only. Between faster and slower excerpts, notes of the same rhythmic value take up less time in the faster excerpts, and may be more likely to be judged as light and separate, regardless of what the actual articulation was. Slow tempo and legato are associated differently. In terms of performance practice or pedagogy, slow notes are often intended to be connected as smoothly as possible, in order to create a sense of continuity. In terms of genre and harmony, while jazz/blues (on the third dimension) is the most extreme example of this, many genres have harmonies associated with them. For example, the classical genre has fairly structured rules for both harmony and voice leading, but the romantic era relaxed those rules and introduced more complex harmonies. The gradual devolution of those rules and the increase in complexity of harmony continued through the modern and contemporary styles. Although these specific contributions aren't as strong as some of the others, a glance back at the factor scores plot shows that the older styles: baroque, classical, and romantic, are both negative on the 2nd dimension, as are the simpler harmonies of major and minor. Likewise the newer western styles: impressionist, modern, and contemporary, load positively on the 2nd dimension, along with the more complex harmonies of chromatic, whole tone, and ambiguous. Historically speaking, the whole tone scale gained great popularity with composers in the impressionist era. 
  However, because of the nature of this survey, this tells us more about the excerpts specifically than the behavior of the participants. Because the excerpts were composed with the intent of varying across all of these musical dimensions, what we see is a sort of validation that there is, in fact, that variety among these excerpts, and that they are different enough to create a large and varied factor space. 

```{r factormaps.Q, fig.height = 8, fig.show = 'hold', out.width='100%'}

axisone = 1
axistwo = 2

rownames(FIsym)<- c(1:5,7:13,15:30)
unsignedCJ <- dimcares.inf$Fixed.Data$ExPosition.Data$cj[,1:2]
signedCJ <- dimcares.inf$Fixed.Data$ExPosition.Data$cj * sign(FJs)

sig.colsonly <-  rownames(FJs)[(unsignedCJ[,1] > (1/nrow(FJs))) | 
                                 (unsignedCJ[,2] > (1/nrow(FJs))) ]

sig.FJs <- FJs[sig.colsonly,1:4]

col4sigcolsonly <- col4cols[(unsignedCJ[,1] > (1/nrow(FJs))) | 
                              (unsignedCJ[,2] > (1/nrow(FJs))) ]

mat6 <- as.matrix(catadata.list$contingency[c(6,14),])
colnames(mat6) <- colnames(catadata.list$contingency)

#test <- epCA(musdimdata.no6, 
#                  masses= NULL, weights= NULL, 
#                 hellinger = FALSE, symmetric = TRUE, 
#                 graphs =FALSE)

proj6 <- supplementaryRows(mat6, dimcares.inf$Fixed.Data)

rownames(proj6$fii) <- c("6","14")

scoresw6 <- rbind(FIsym, proj6$fii)

cols4proj <- c(col4exgrp, gplots::col2hex(c("blueviolet", "blueviolet")))

exmap.sym.12 <- createFactorMapIJ(scoresw6,
                                sig.FJs,
                                axis1 = axisone,axis2 = axistwo,
                                col.points.i = cols4proj, 
                                col.labels.i = cols4proj, 
                                col.points.j = col4sigcolsonly, 
                                col.labels.j = col4sigcolsonly,
                                text.cex.i = 4, text.cex.j = 2.5,
                                cex.i = 4, cex.j = 4,
                                font.face.j = "italic",
                                alpha.labels.i = 1, alpha.labels.j = 1
                                )

vc.labels.12 <- createxyLabels(resCA = dimcares.inf$Fixed.Data)

#ti.qs.12 <- MakeToleranceIntervals(scoresw6)

mus.012 <- exmap.sym.12$baseMap +  
            exmap.sym.12$I_points + 
              exmap.sym.12$I_labels + 
                exmap.sym.12$J_points + 
                  exmap.sym.12$J_labels + 
                    vc.labels.12 + ggtitle('Dimensions 1 and 2')
  
axisone = 3
axistwo = 2

exmap.sym.23 <- createFactorMapIJ(scoresw6,
                                sig.FJs,
                                axis1 = axisone,axis2 = axistwo,
                                col.points.i = cols4proj, 
                                col.labels.i = cols4proj, 
                                col.points.j = col4sigcolsonly, 
                                col.labels.j = col4sigcolsonly,
                                text.cex.i = 4, text.cex.j = 2.5,
                                font.face.i = "italic",
                                alpha.labels.i = 1, alpha.labels.j = 1
                                )

vc.labels.23 <- createxyLabels(resCA = dimcares.inf$Fixed.Data, 
                               x_axis = axisone,
                               y_axis = axistwo)

mus.023 <- exmap.sym.23$baseMap + #zePoly.J + 
            exmap.sym.23$I_points + 
              exmap.sym.23$I_labels + 
                exmap.sym.23$J_points + 
                  exmap.sym.23$J_labels + 
                    vc.labels.23 + ggtitle('Dimensions 2 and 3')


print(mus.012)
#grid.arrange(
#    as.grob(mus.012),as.grob(mus.023),
#    ncol = 2,nrow = 1,
#    top = textGrob("Symmetric Maps of the Row and Column Factor Scores", gp = gpar(fontsize = 18, font = 3))
#  )

#mus.012.023 <- recordPlot()


```




## Experiment 2: Musical Adjectives Survey

```{r Adatain}
rm(list = ls())

load("adj.catadata.list.RData")
load("excerptsdesign.RData")
load("adjdesign.RData")
load("adjectivecolors.RData")

partcols <- adj.catadata.list$partcols
adjbrick <- adj.catadata.list$adjbrick
adj.contingency <- adj.catadata.list$adjcontingency
adjcols <- adj.catadata.list$adjcols
listofwords <- adj.catadata.list$listofwords

nat.factor <- partcols$nationality
col4nat <- nat.factor
nat.factor <- as.factor(nat.factor)

train.factor <- as.double(partcols$tr_yrs)
train.factor[train.factor < 2] <- "Tr.none"
train.factor[train.factor >= 2 & train.factor <= 5] <- "Tr.little"
train.factor[train.factor != "Tr.none" & train.factor != "Tr.little"] <- "Tr.some"
train.factor <- as.factor(train.factor)

gen.factor <- partcols$gender
gen.factor[gen.factor != "Female" & gen.factor != "Male" 
           & gen.factor != "Femme" & gen.factor != "Homme"] <- "NB"
gen.factor[gen.factor == "Female" | gen.factor == "Femme"] <- "F"
gen.factor[gen.factor == "Male" | gen.factor == "Homme"] <- "M"
gen.factor <- as.factor(gen.factor)

```

```{r A.CA}
adjsym.cares <- epCA(adj.contingency, 
                     symmetric = TRUE)

adjrenorm <- CARenormalization(adjsym.cares$ExPosition.Data$fi,
                               delta = adjsym.cares$ExPosition.Data$pdq$Dv,
                               singularValues = T,
                               masses = adjsym.cares$ExPosition.Data$M
                               )

FIsym.adj <- adjsym.cares$ExPosition.Data$fi
FIasym.adj <- adjrenorm$G_A
FJs.adj <- adjsym.cares$ExPosition.Data$fj
CAEigs.adj <- adjsym.cares$ExPosition.Data$eigs
```

```{r inferences.A, cache = TRUE}
# Bootstrapping
bootCA.adj <- Boot4PTCA(ZeDataCube = adjbrick,
                        fi = FIsym.adj,
                        fj = FJs.adj,
                        eigs = CAEigs.adj,
                        nf2keep = 3,
                        nBootIter = 500)
# Compute Bootstrapped ratios
bootRatadj.I <- PTCA4CATA::boot.ratio.test(bootCA.adj$RowsBoot,
                                            critical.value = 2)
bootRatadj.J <- PTCA4CATA::boot.ratio.test(bootCA.adj$ColumnsBoot,
                                              critical.value = 2)
# Probabilities 
probBRadj.I  <- bootRatadj.I$prob.boot.ratios
probBRadj.J  <- bootRatadj.J$prob.boot.ratios

# Permutation tests
adjca.inf <- perm4PTCA(aCube = adjbrick,
                       nIter = 1000,
                       permType = 'byRows' ,
                       Malinvaud = TRUE)
Ind.Permu.adj    <- adjca.inf$permInertia
InertiaFixed.adj <- adjca.inf$fixedInertia
prob.cpt.lst.adj <- adjca.inf$MalinvaudQ['p-perm',]
# Get the p values for the components
prob.cpt.adj <- (unlist(prob.cpt.lst.adj[2:length(prob.cpt.lst.adj)]))
prob.cpt.adj[is.na(prob.cpt.adj)] <- 1
```

```{r partdistance.A}

Cmat.adj <- createSymDist4PTCA(adjbrick)$CrossProduct

eigenCmat.adj <- eigen(Cmat.adj, symmetric = TRUE)
eig4Cmat.adj <-  eigenCmat.adj$values
tau4Cmat.adj <- round( (100*eig4Cmat.adj) / sum(eig4Cmat.adj))

nk       <- 3
F4Cmat.adj   <- eigenCmat.adj$vectors[,1:nk] %*% diag(eig4Cmat.adj[1:nk]^(1/2))

rownames(F4Cmat.adj) <- rownames(Cmat.adj)
```

### Participants

The scree plot depicted in \@ref(fig:a.part.scree) shows the explained variance per dimension for the distance analysis of participants in the adjectives survey. Again, having a high number of participants means that the dimensionality is high, and each dimension is only extracting a little bit of variance. However, the first five dimensions all have $\lambda$ > 1: `r round(eig4Cmat.adj[1], 2)`, `r round(eig4Cmat.adj[2], 2)`, `r round(eig4Cmat.adj[3], 2)`, `r round(eig4Cmat.adj[4], 2)`, and `r round(eig4Cmat.adj[5], 2)`, respectively. However, because of the high dimensionality here, the first dimension extracts only ~3% of the overall variance, the second dimension extracts only ~2%, and each successive dimension extracts incrementally less. 

```{r a.part.scree}
ScreeInf <- PlotScree(ev = eig4Cmat.adj,
             max.ev = NULL, alpha = 0.05,
             col.ns = "#006D2C", col.sig = "#54278F",
             title = "Participants Distance Analysis, Adjectives Survey: \nExplained Variance per Dimension",
             plotKaiser = T)

a000.adj.screeRV <-  recordPlot()
```  
  
  MDS of a distance matrix calculated from the pages of the brick revealed significant group differences in how French and American participants described the excerpts, $\textit p$. < .01. The factor scores of the participants are plotted below, with with group means and bootstrapped confidence intervals shown for those means. The bootstrapping resampling was performed with 1000 iterations. We also analyzed the dating using two other participant groupings as factors: gender identity, with three levels: Male, Female, or Non-Binary, and level of music training, with three levels: < 2 years, 2-5 years, and >5 years. Neither of these analyses revealed any significant differences between groups.  

```{r map4RV.A, fig.height=6}
Shortnames4Participants <-  dimnames(adjbrick[[3]])
F4Plot <- F4Cmat.adj
rownames(F4Plot) <- Shortnames4Participants
# Make labels
labels4RV <- createxyLabels.gen(1,2,lambda = eig4Cmat.adj, tau = tau4Cmat.adj)

#Here we calculate the means for the factor groupings, and then bootstrap them:
n.adjmeans <- getMeans(F4Plot, nat.factor)
BootCadj.N <- PTCA4CATA::Boot4Mean(F4Cmat.adj, design = nat.factor,
                                   niter = 1000,
                                   suppressProgressBar = TRUE)
dimnames(BootCadj.N$BootCube)[[2]] <- paste0('Dimension ',
                                             1:dim(BootCadj.N$BootCube)[[2]])
# Create ellipses for the map
n.elliadj <- MakeCIEllipses(BootCadj.N$BootCube[,1:2,],
                            names.of.factors = c("Dimension 1", "Dimension 2"),
                            col = cols$n.gc)
#Base map
BaseMap.Participants <- createFactorMap(X = F4Plot ,
                              axis1 = 1, axis2 = 2,
                              display.points = TRUE,
                              col.points = cols$n.oc,
                              pch = 19, cex = 2.5,
                              display.labels = TRUE,
                              col.labels = cols$n.oc,
                              text.cex = 4, font.face = "bold",
                              font.family = "sans",
                              col.axes = "darkorchid", 
                              alpha.points = .25,
                              alpha.axes = 0.2,
                              width.axes = 1.1,
                              col.background = adjustcolor("lavender",
                                                       alpha.f = 0.2),
                              force = 1, segment.size = 3)

#Nationality map
title4RV <- "Rv Analysis of Participants \nIncluding Group Means and Confidence Intervals"
n.rv.means <- createFactorMap(n.adjmeans,
                              axis1 = 1, axis2 = 2, 
                              constraints = BaseMap.Participants$constraints, 
                              col.points =  cols$n.gc,
                              alpha.points = 1, # no transparency
                              alpha.labels = 1,
                              display.points = TRUE,
                              pch = 17, cex = 5,
                              display.labels = TRUE, 
                              title = title4RV,
                              col.labels = cols$n.gc, 
                              text.cex = 6,font.face = "bold",
                              font.family = "sans", col.axes = "darkorchid", 
                              alpha.axes = 0.2, width.axes = 1.1, 
                              col.background = adjustcolor("lavender", alpha.f = 0.2), 
                              force = 1, segment.size = 0)

a.03adj.map4part <- BaseMap.Participants$zeMap_background + 
                  n.rv.means$zeMap_text + n.rv.means$zeMap_dots +
                    BaseMap.Participants$zeMap_dots + n.elliadj + labels4RV


print(a.03adj.map4part + ggtitle(title4RV))
```

### Excerpts

```{r}
adj.tau <- adjsym.cares$ExPosition.Data$t
```

  The plot below shows the explained variance per dimension in the analysis of the excerpts contingency table. Although there are no components with $\lambda$ > 1, there are two strong dimensions that extract a majority of the variance. The first two dimensions extract `r round(sum(adj.tau[c(1,2)]), 2)`% of the variance, with the first dimension extracting a majority: `r round(adj.tau[1], 2)`%, and the second dimension extracting almost a quarter of the overall variance: `r round(adj.tau[1],2)`%. This plot also suggests that there are multiple 'elbows', at the 3rd, 5th, and 7th dimensions, respectively, with the third and fourth dimensions forming an 'eigen-plane', of two dimensions which extract similar amounts of variance and should be considered together. For this analysis, however, we're focused on the two first dimensions.
  Although excerpts 6 and 14 are outliers in the musical qualities survey, for reasons detailed above, they were not outliers in this analysis. We therefore included them in all of the analyses for Experiment 2.
```{r scree4descriptors}
adj.scree <- PlotScree(adjsym.cares$ExPosition.Data$eigs, 
                       p.ev = adjca.inf$pEigenvalues,
                       plotKaiser = T, color4Kaiser = "red")
  
mus.00.scree <- recordPlot()
```

  Contributing significantly to the positive end of the first dimension are excerpts from group three (green) and to the negative end are excerpts from group one (yellow). Strong contributions on the positive end of the dimension from the adjectives "Sad", "Dark", "Melancholy", "Slow", "Mysterious", "Solemn", and "Disturbing". The negative end of the first dimension is defined by the adjectives "Fast", "Happy", "Dancing", "Colorful", and "Bright". 
  The second dimension is dominated by excerpts from group 4 (red) in the positive direction and group 2 (blue) in the negative direction. Two excerpts from group 3 also contribute significantly, excerpts 7 in the positive direction and excerpt 10 in the negative direction. The columns contributing strongly in the positive direction are "Aggressive", "Fast", "Disturbing", "Mysterious", "Surprising" and "Complex". The columns contributing in the negative direction are "Warm, "Soft", "Happy", "Slow", "Round", and "Light".  

```{r justsomeconts.A}

signed.ctrI.adj <- adjsym.cares$ExPosition.Data$ci * sign(FIsym.adj)
signed.ctrJ.adj <- adjsym.cares$ExPosition.Data$cj * sign(FJs.adj)

CIlist <- vector(mode = "list", length = 2)
CJlist <- vector(mode = "list", length= 2)

names(CIlist) <- c("Dim1", "Dim2")
names(CJlist) <- c("Dim1", "Dim2")

for (i in 1:3){
  CIlist[[i]] <- signed.ctrI.adj[which(abs(signed.ctrI.adj[,i]) > 1/nrow(signed.ctrI.adj)),i]
  CJlist[[i]] <- signed.ctrJ.adj[which(abs(signed.ctrJ.adj[,i]) > 1/nrow(signed.ctrJ.adj)),i]
}
```

```{r contributions.A}
# plot contributions of rows for component 1
ctradjI.1 <- PrettyBarPlot2(CIlist[[1]],
                         threshold = 1 / NROW(signed.ctrI.adj),
                         font.size = 3,
                         color4bar = cols$ex.oc[which(abs(signed.ctrI.adj[,1]) > 1/nrow(signed.ctrI.adj))], # we need hex code
                         ylab = 'Contributions',
                         #sortValues = TRUE,
                         ylim = c(1.2*min(CIlist[[1]]), 1.2*max(CIlist[[1]]))
) + ggtitle("Component 1", subtitle = 'Rows')

# plot contributions of columns for component 1
ctradjJ.1 <- PrettyBarPlot2(CJlist$Dim1,
                         threshold = 1 / NROW(signed.ctrJ.adj),
                         font.size = 3,
                         color4bar = cols$adj.oc[which(abs(signed.ctrJ.adj[,1]) > 1/nrow(signed.ctrJ.adj))], # we need hex code
                         ylab = 'Contributions',
                        # sortValues = TRUE,
                         ylim = c(1.2*min(CJlist[[1]]), 1.2*max(CJlist[[1]]))
) + ggtitle("", subtitle = 'Columns')

# plot contributions of rows for component 2
ctradjI.2 <- PrettyBarPlot2(CIlist[[2]],
                         threshold = 1 / NROW(signed.ctrI.adj),
                         font.size = 3,
                         color4bar = cols$ex.oc[which(abs(signed.ctrI.adj[,2]) > 1/nrow(signed.ctrI.adj))], # we need hex code
                         ylab = 'Contributions',
                        # sortValues = TRUE,
                         ylim = c(1.2*min(signed.ctrI.adj[,2]), 1.2*max(signed.ctrI.adj[,2]))
) + ggtitle("Component 2", subtitle = 'Rows')

# plot contributions of columns for component 2
ctradjJ.2 <- PrettyBarPlot2(CJlist$Dim2,
                         threshold = 1 / NROW(signed.ctrJ.adj),
                         font.size = 3,
                         color4bar = cols$adj.oc[which(abs(signed.ctrJ.adj[,2]) > 1/nrow(signed.ctrJ.adj))], # we need hex code
                         ylab = 'Contributions',
                        # sortValues = TRUE,
                         ylim = c(1.2*min(signed.ctrJ.adj[,2]), 1.2*max(signed.ctrJ.adj[,2]))
) + ggtitle("", subtitle = 'Columns')

grid.arrange(
    as.grob(ctradjI.1),as.grob(ctradjJ.1),
    as.grob(ctradjI.2),as.grob(ctradjJ.2),
    ncol = 2,nrow = 2,
    top = textGrob("Contributions", gp = gpar(fontsize = 18, font = 3))
  )

Ctradj.IJ <- recordPlot()

#yellow is 1, blue is 2, green is 3, red is 4.

```

  The barplots in \@ref(fig:theboots.A) show the bootstrap ratios calculated for the rows and columns. Here we've included all of the rows and columns, because it's useful to see both which are significant and which are not. This is an inferential method that tells us is how consistently each of the observations and variables load on the first two dimensions. The threshold in this case is *p* < .05. From this we get an idea of which of the rows and columns are stable, in other words, which ones tended to be rated in a certain way consistently across all participants, and also how likely these are to be observations reflective of the population as a whole. In this plot, the more extreme value of the bootstrap ratio, the more likely that it is a reflection of the 'real' value. The values in the center of each plot that are grayed out identify the rows or columns that are not consistently loading on the dimensions. With the observations and variables ordered like this, it makes it easy to see how the consistently the clusters are distributed in the space. This plot was not included for experiment 1 because it would be less informative given what the survey in experiment 1 was assessing. Experiment 1 doesn't evaluate the behavior of participants, but the nature of the excerpts.
  Note that there are far more significant bootstrap ratios than there are significant contributions. That just means that while not everything is contributing, overall the model seems to be stable. Fewer significant bootstrap ratios would suggest that there was a greater amount of variance in the observations and variables than were accounted for, at least in the first two dimensions. Looking at the nonsignificant values for the adjectives may inform our understanding of the participants' use of the adjectives. 'Incisive', 'transparent', 'poweful', 'dense', 'round', and 'sparse', are all nonsignificant on the first dimension, and 'weak', 'dull', 'sparse', 'valiant', and 'short' are all nonsignificant on the second dimension. All but 'sparse' are significant on one dimension or the other. Looking at the column sum for 'sparse' tells us that it was used, so this isn't an effect of participants not using this word. It's more likely that 'sparse' doesn't really fit into the Valence-arousal plane. It's a neutrally valenced word that could describe excerpts that fall anywhere within that plane. 'Weak' and 'transparent' give us another important perspective. These were the two least commonly used adjectives, but the fact that they are consistently loading on one dimension or the other suggests that when they were used, they were used in the same way. 
  
```{r bootstraps}
BR.I <- bootRatadj.I$boot.ratios
BR.J <- bootRatadj.J$boot.ratios

laDim = 1

# Plot the bootstrap ratios for Dimension 1
badj001.BR1.I <- PrettyBarPlot2(BR.I[,laDim],
                        threshold = 2,
                        font.size = 3,
                   color4bar = cols$ex.oc[order(BR.I[,laDim])], # we need hex code
                  ylab = 'Bootstrap ratios',
                  sortValues = TRUE,
) + ggtitle(paste0('Component ', laDim), subtitle = 'Rows')

badj002.BR1.J <- PrettyBarPlot2(BR.J[,laDim],
                        threshold = 2,
                        font.size = 3,
                   color4bar = cols$adj.oc[order(BR.J[,laDim])],
                  ylab = 'Bootstrap ratios',
                  sortValues = TRUE,
) + ggtitle("", subtitle = 'Columns')

# Plot the bootstrap ratios for Dimension 2
laDim = 2
badj003.BR2.I <- PrettyBarPlot2(BR.I[,laDim],
                        threshold = 2,
                        font.size = 3,
                   color4bar = cols$ex.oc[order(BR.I[,laDim])], # we need hex code
                  ylab = 'Bootstrap ratios',
                  sortValues = TRUE,
) + ggtitle(paste0('Component ', laDim), subtitle = 'Rows')

badj004.BR2.J <- PrettyBarPlot2(BR.J[,laDim],
                        threshold = 2,
                        font.size = 3,
                   color4bar = cols$adj.oc[order(BR.J[,laDim])],
                  ylab = 'Bootstrap ratios',
                  sortValues = TRUE, 
) + ggtitle("", subtitle = 'Columns')

```

```{r theboots.A, fig.width=14}

grid.arrange(
    as.grob(badj001.BR1.I),as.grob(badj002.BR1.J),
    as.grob(badj003.BR2.I),as.grob(badj004.BR2.J),
    ncol = 2,nrow = 2,
    top = textGrob("Bootstrap ratios", gp = gpar(fontsize = 18, font = 3))
  )

BRadj.IJ <- recordPlot()

```  

### Discussion
  
  The factor maps below show the row and column factor scores for the american and french participants. These are once again symmetric plots, interpretation is the same as the factor plot for the musical qualities. There's a clear valence-arousal plane apparent for both, and in both cases valence seems to define the first dimension and arousal defines the second dimension. However, the difference in the amount of variance extracted by the first two dimensions between the french and american participants is notable. The french data show a weaker first dimension but a stronger second dimension relative to the americans, both in terms of variance extracted (tau), effect size (lambda). This tells us that french participants were less affected by the excerpts than the american participants, but they responded more to the arousal of the excerpts.
  There are also differences in how the adjectives and the excerpts are distributed in the space. One clear example is that Excerpt 6 is in quadrant two in the american plot, but quadrant one in the french. This is a small change, but it suggests that the french participants were more likely to assign negative valence to this excerpt, and American Participants were more likely to assign positive valence. For the adjectives, 'bright' and 'dancing' are directly on top of one another in the American plot, but there is some space between the two in the French plot.  It's possible that this reflects the idea that although the meaning is shared between languages, there are semantic or associational differences between the words.

```{r factormaps.A, fig.height = 10, fig.show = 'hold', out.width='100%'}

adjbrick.AM <- adjbrick[,,1:length(which(adj.catadata.list$partcols$nationality == "AM"))]
adj.cont.AM <- apply(adjbrick.AM, c(1,2), sum)

adjbrick.FR <- adjbrick[,,(length(which(adj.catadata.list$partcols$nationality == "AM"))+1):dim(adjbrick)[[3]]]
adj.cont.FR <- apply(adjbrick.FR, c(1,2), sum)

adj.fr.cares <- epCA(adj.cont.FR, symmetric = TRUE)
adj.am.cares <- epCA(adj.cont.AM, symmetric = TRUE)

adj.fr.cares$ExPosition.Data$fi[,2] <- adj.fr.cares$ExPosition.Data$fi[,2]*-1
adj.fr.cares$ExPosition.Data$fj[,2] <- adj.fr.cares$ExPosition.Data$fj[,2]*-1

am.FI <- adj.am.cares$ExPosition.Data$fi
am.FJ <- adj.am.cares$ExPosition.Data$fj

fr.FI <- adj.fr.cares$ExPosition.Data$fi
fr.FJ <- adj.fr.cares$ExPosition.Data$fj

rownames(am.FI) <- rownames(fr.FI) <- rownames(FIsym.adj) <- c(1:30)


colnames(adjrenorm$G_A) <- colnames(FJs.adj)

axisone <- 1
axistwo <- 2

exmap <- createFactorMapIJ(FIsym.adj,
                           FJs.adj,
                           axis1 = axisone,axis2 = axistwo,
                           col.points.i = cols$ex.oc, 
                           col.labels.i = cols$ex.oc, 
                           col.points.j = cols$adj.oc, 
                           col.labels.j = cols$adj.oc,
                           text.cex.i = 3.5, text.cex.j = 3.5,
                           font.face.j = 'italic',
                           
                           )

vc.labels <- createxyLabels(resCA = adjsym.cares)

am.labels <- createxyLabels(resCA = adj.am.cares)

fr.labels <- createxyLabels(resCA = adj.fr.cares)

exmap.am <- createFactorMapIJ(am.FI,
                                am.FJ,
                                axis1 = axisone,axis2 = axistwo,
                                col.points.i = cols$ex.oc, 
                                col.labels.i = cols$ex.oc, 
                                col.points.j = cols$adj.oc, 
                                col.labels.j = cols$adj.oc,
                                text.cex.i = 5, text.cex.j = 3.5, font.face.j = 'italic'
                                
                                )



exmap.fr <- createFactorMapIJ(fr.FI,
                                fr.FJ,
                                axis1 = axisone,axis2 = axistwo,
                                col.points.i = cols$ex.oc, 
                                col.labels.i = cols$ex.oc, 
                                col.points.j = cols$adj.oc, 
                                col.labels.j = cols$adj.oc,
                                text.cex.i = 5, text.cex.j = 3.5, font.face.j = 'italic'
                                )


mus.adj.am <- exmap.am$baseMap + 
            exmap.am$I_points + 
              exmap.am$I_labels + 
                exmap.am$J_points + 
                  exmap.am$J_labels + 
                    am.labels + ggtitle('American Participants')

mus.adj.fr <- exmap.fr$baseMap +  
            exmap.fr$I_points + 
              exmap.fr$I_labels + 
                exmap.fr$J_points + 
                  exmap.fr$J_labels + 
                    fr.labels + ggtitle('French Participants')

mus.adj.004 <- exmap$baseMap + #zePoly.J + 
            exmap$I_points + 
              exmap$I_labels + 
                exmap$J_points + 
                  exmap$J_labels + 
                    vc.labels + ggtitle('Symmetric Map of Row and Column Factor Scores')
  

grid.arrange(
    as.grob(mus.adj.am),as.grob(mus.adj.fr),
    ncol = 2,nrow = 1, 
    top = textGrob("Symmetric Maps of the Row and Column Factor Scores", gp = gpar(fontsize = 18, font = 3))
 )

am_fr_adjmaps <- recordPlot()


#print(mus.adj.004)
```


```{r A.MFA.ex, fig.height=10, message=FALSE, warning=FALSE, include = FALSE}
suppressMessages(library(MExPosition))

adj4MFA <- abind(adj.cont.FR, adj.cont.AM, along = 2)

frvec <- t(as.data.frame(rep("FR", length.out = dim(adj.cont.FR)[2])))
amvec <- t(as.data.frame(rep("AM", length.out = dim(adj.cont.AM)[2])))

colnames(frvec) <- colnames(amvec) <- colnames(adj.cont.FR)
rownames(frvec) <- rownames(amvec) <- "group"


mfagroups <- abind(frvec, amvec, along = 2)


mfares <- mpMFA(adj4MFA, mfagroups)

renameCols <- function(x){
   colnames(x) <- paste("Dimension", 1:ncol(x))
   x
}

RVmat <- mfares$mexPosition.Data$InnerProduct$RVMatrix

#corrplot(RVmat, method = "color", addCoefasPercent = TRUE) 

Eig4scree <- mfares$mexPosition.Data$Table$eigs

#mfascree <- PlotScree(Eig4scree, plotKaiser = TRUE)

MFA_FMap <- createFactorMap(
                            mfares$mexPosition.Data$Table$fi,
                            col.points = cols$ex.oc,
                            col.labels = cols$ex.oc,
                            alpha.points = .6,
                            pch = 17,
                            cex = 5,
                            display.labels = TRUE,
                            constraints = minmaxHelper4Partial(FactorScores = mfares$mexPosition.Data$Table$fi,
                              partialFactorScores = mfares$mexPosition.Data$Table$partial.fi.array)
                            )
                            
label4Map <- createxyLabels.gen(1,2,
                                lambda = mfares$mexPosition.Data$Table$eigs,
                                tau = mfares$mexPosition.Data$Table$t,
                                axisName = "Dimension ")




fi4pfs <- mfares$mexPosition.Data$Table$fi

fi4pfs <- renameCols(fi4pfs)

pfi4pfs <- mfares$mexPosition.Data$Table$partial.fi.array

pfi4pfs <- renameCols(pfi4pfs)

rownames(pfi4pfs) <- c(1:30)

dimnames(pfi4pfs)[[3]] <- c("FR", "AM")

map4PFS <- createPartialFactorScoresMap(
                                        factorScores = fi4pfs,
                                        partialFactorScores = pfi4pfs,
                                        axis1 = 1, axis2 = 2,
                                        colors4Items = cols$ex.oc,
                                        names4Partial = c("FR", "AM"),
                                        font.labels = 'bold'
                                        )

partialfsmap <- MFA_FMap$zeMap + 
                  label4Map + 
                    map4PFS$linesColByItems + 
                      map4PFS$pointsColByItems + 
                        map4PFS$labelsColByItems +
                          ggtitle("Contributions to the Excerpts Factor Scores")

adj4MFA.T <- abind(t(adj.cont.FR), t(adj.cont.AM), along = 2)

natvec <- rep(c("FR", "AM"), times = dim(adj4MFA.T)[2]/2)
natvec <- data.frame(natvec[order(natvec, decreasing = T)]) %>% t(.)

colnames(natvec) <- colnames(adj4MFA.T)
rownames(natvec) <- "group"

mfares.t <- mpMFA(adj4MFA.T, natvec)

RVmat.t <- mfares.t$mexPosition.Data$InnerProduct$RVMatrix

#corrplot(RVmat, method = "color", addCoefasPercent = TRUE) 

Eig4scree <- mfares$mexPosition.Data$Table$eigs

#mfascree <- PlotScree(Eig4scree, plotKaiser = TRUE)

MFA_FMap.t <- createFactorMap(
                            mfares.t$mexPosition.Data$Table$fi,
                            col.points = cols$adj.oc,
                            col.labels = cols$adj.oc,
                            alpha.points = .6,
                            pch = 17,
                            cex = 5,
                            display.labels = TRUE,
                            constraints = minmaxHelper4Partial(FactorScores = mfares.t$mexPosition.Data$Table$fi,
                              partialFactorScores = mfares.t$mexPosition.Data$Table$partial.fi.array)
                            )
                            
label4Map.t <- createxyLabels.gen(1,2,
                                lambda = mfares.t$mexPosition.Data$Table$eigs,
                                tau = mfares.t$mexPosition.Data$Table$t,
                                axisName = "Dimension ")




fi4pfs.t <- mfares.t$mexPosition.Data$Table$fi

fi4pfs.t <- renameCols(fi4pfs.t)

pfi4pfs.t <- mfares.t$mexPosition.Data$Table$partial.fi.array

pfi4pfs.t <- renameCols(pfi4pfs.t)

rownames(pfi4pfs.t) <- colnames(adj.contingency)

dimnames(pfi4pfs.t)[[3]] <- c("FR", "AM")

map4PFS.t <- createPartialFactorScoresMap(
                                        factorScores = fi4pfs.t,
                                        partialFactorScores = pfi4pfs.t,
                                        axis1 = 1, axis2 = 2,
                                        colors4Items = cols$adj.oc,
                                        names4Partial = c("FR", "AM"),
                                        font.labels = 'bold', 
                                       # alpha.lines = .75, size.lines = 3
                                        )


partialfsmap.t <- MFA_FMap.t$zeMap + 
                  label4Map.t + 
                    map4PFS.t$linesColByItems + 
                      map4PFS.t$pointsColByItems + 
                        map4PFS.t$labelsColByItems +
                          ggtitle("Contributions to the Adjectives Factor Scores")
```


Additionally, a post-hoc Multiple Factor Analysis revealed the following in terms of the semantic and perceptual differences between French and American participants.

```{r mfasbs, fig.height=8, out.width='45%', ncols = 2, fig.show='hold'}

print(partialfsmap)
print(partialfsmap.t)
#grid.arrange(as.grob(partialfsmap),
#             as.grob(partialfsmap.t),
#             ncol = 2, nrow = 1,
#             top = textGrob("Partial Factor Scores Plots for French and American Participants")
#             )

#mfasbs <- recordPlot()
```



## Experiment 3: Combined Surveys

```{r loadthedataPLSC}
rm(list = ls())

load("catadatamusdim.RData")
load("adj.catadata.list.RData")
load("adjdesign.RData")
load("adjectivecolors.RData")

source('~/GitHub/MusicDescriptorsBackup/barplot_sigonly.R')

dimcontingency <- catadata.list$contingency
adjcontingency <- adj.catadata.list$adjcontingency

dimcontingency <- dimcontingency[-c(6,14),-9]
adjcontingency <- adjcontingency[-c(6,14),]

```

```{r}
library(TExPosition)
library(TInPosition)
library(data4PCCAR)
pls.res <- tepPLS(dimcontingency, adjcontingency, DESIGN = adj.design$thedesign[-c(6,14)])
resPerm4PLSC <- perm4PLSC(dimcontingency, adjcontingency, nIter = 1000)

```

```{r thefirst3eigs}

e1 <- pls.res$TExPosition.Data$eigs[1]
e2 <- pls.res$TExPosition.Data$eigs[2]
e3 <- pls.res$TExPosition.Data$eigs[3]

t1 <- pls.res$TExPosition.Data$t[1]
t2 <- pls.res$TExPosition.Data$t[2]
t3 <- pls.res$TExPosition.Data$t[3]
t4 <- pls.res$TExPosition.Data$t[4]

```

  Experiment 3 used the pseudo-contingency tables from experiments 1 and 2 together. Since excerpts 6 and 14 were excluded from analysis for experiment 1, we also removed those rows from the contingency table for experiment 2. This is so that the dimensions of the two tables for this PLSC would be conformable (remember that we need the same rows or columns in both tables for this analysis). The point of this experiment is to identify the strongest covariance between the two tables - that is, the strongest shared signal between two data tables. Now, this is not to say that these two tables are evaluating the same thing. Instead it allows us to see what is most common between two sets of different information - how often an excerpt was associated with *both* a musical quality and an adjective. The visualizations below allow us to see which variables from each of the two tables correspond with one another; which adjectives are associated with which musical dimensions. Even though both individual tables have their own factor spaces, plotting the common factor space between the two should allow us to see which excerpts are separated from one another using data from both surveys.

### Results

This analysis revealed two dimensions that extracted the majority of the variance (`r round(sum(t1,t2), 2)`%). Of that total extracted by the first two dimensions, the first dimension extracted `r round(t1, 2)`% and the second dimension extracted `r round(t2, 2)`%. The scree plot below shows that it's possible that there are two elbows in this graph, at the 3rd and 5th dimensions. The 3rd and 4th dimensions are also significant, extracting `r round(t3, 2)`% and `r round(t4, 2)`% of the variance, respectively. Interpretations of the third dimension and beyond is beyond the scope of this paper, but seeing that there are multiple significant dimensions beyond the second does provide a possible future direction using this method.  

```{r screePLSC}

PlotScree(ev = pls.res$TExPosition.Data$eigs,
          p.ev = resPerm4PLSC$pEigenvalues,
          title = 'PLSC Music Features: Inertia Scree Plot',
          plotKaiser = TRUE, 
          color4Kaiser = ggplot2::alpha('darkorchid4', .5),
          lwd4Kaiser  = 2
          )
a000.scree4plsc <-  recordPlot()

```

  The plot below shows which variables from each data table load the most on the first and second dimensions. For the purposes of this visualization, we are showing only the variables for which 70% or more of the variance is explained. The nature of the PLSC also suggests that these are the variables that are most associated with one another between the two tables. The strongest signal on the first dimension juxtaposes the slow and legato musical qualities in the positive direction with the fast, staccato, marcato, and conjunct musical qualities in the negative direction. The adjectives associated with the qualities in the positive direction are "Dark", "Dull", "Long", "Melancholy", "Sad", "Slow", "Solemn", and "Weak." The adjectives associated with the negative direction are "Bright", "Colorful", "Dancing", "Fast", "Happy", and "Light".  
  The second dimension identified in the positive direction major harmony and mezzo dynamics, associated with "Light", "Round", "Soft", and "Warm." The negative direction is driven by the impressionist genre being associated with "Aggressive", "Complex", "Dense", "Disturbing", "Powerful", and "Surprising".

```{r loadingsplsc, fig.width = 10,  fig.height = 4, fig.show='hold', message=F}

ps <- pls.res$TExPosition.Data$pdq$p
qs <- pls.res$TExPosition.Data$pdq$q

th <- .7

pslist <- vector(mode = "list", length = 2)
qslist <- vector(mode = "list", length= 2)

names(qslist) <- c("Dim1", "Dim2")
names(pslist) <- c("Dim1", "Dim2")

p.names <- rownames(ps)
q.names <- rownames(qs)

for (i in 1:2){
  pslist[[i]] <- ps[which(abs(ps[,i]) > th*max(abs(ps[,i]))),i]
  qslist[[i]] <- qs[which(abs(qs[,i]) > th*max(abs(qs[,i]))),i]
  names(pslist[[i]]) <- p.names[abs(ps[,i]) > th*max(abs(ps[,i]))]
  names(qslist[[i]]) <- q.names[abs(qs[,i]) > th*max(abs(qs[,i]))]
  }

colors4plsc <- vector(mode = "list", length = 5)
names(colors4plsc) <- c("colors", "p.all","q.all","p.vec", "q.vec" )

colors4plsc$colors <- c(wes_palettes$Darjeeling1[c(1,2,4)],
                        wes_palettes$Darjeeling2[2])

colors4plsc$p.all <- ps
colors4plsc$p.all[colors4plsc$p.all > 0] <- colors4plsc$colors[1]
colors4plsc$p.all[colors4plsc$p.all != colors4plsc$colors[1]] <- colors4plsc$colors[2]

colors4plsc$q.all <- qs
colors4plsc$q.all[colors4plsc$q.all > 0] <- colors4plsc$colors[3]
colors4plsc$q.all[colors4plsc$q.all != colors4plsc$colors[3]] <- colors4plsc$colors[4]

colors4plsc$p.vec <- vector(mode = "list", length = 2)
colors4plsc$q.vec <- vector(mode = "list", length = 2)

names(colors4plsc$p.vec) <- c("Dim1", "Dim2")
names(colors4plsc$q.vec) <- c("Dim1", "Dim2")


for (i in 1:2){
  colors4plsc$p.vec[[i]] <- colors4plsc$p.all[which(abs(ps[,i]) > th*max(abs(ps[,i]))),i]
  colors4plsc$q.vec[[i]] <- colors4plsc$q.all[which(abs(qs[,i]) > th*max(abs(qs[,i]))),i]

}

loading1 <- PrettyBarPlot2(bootratio = c(pslist$Dim1, qslist$Dim1), 
                       threshold = min(c(th*max(abs(ps[,1])), th*max(abs(qs[,1])))), 
                       ylim = c(1.2*min(c(pslist$Dim1, qslist$Dim1)), 1.2*max(c(pslist$Dim1, qslist$Dim1))),
                       color4bar = c(colors4plsc$p.vec$Dim1, colors4plsc$q.vec$Dim1),
                       color4ns = "gray75", 
                       plotnames = TRUE, 
                       main = 'Loadings for variables for factor plot 1', 
                       ylab = "Signed Loadings"
                       #font.size = 1
                       )
  
loading2 <- PrettyBarPlot2(bootratio = c(pslist$Dim2, qslist$Dim2), 
                       threshold = min(c(th*max(abs(ps[,2])), th*max(abs(qs[,2])))), 
                       ylim = c(1.2*min(c(pslist$Dim2, qslist$Dim2)), 1.2*max(c(pslist$Dim2, qslist$Dim2))),
                       color4bar = c(colors4plsc$p.vec$Dim2, colors4plsc$q.vec$Dim2),
                       color4ns = "gray75", 
                       plotnames = TRUE, 
                       main = 'Loadings for variables for factor plot 2', 
                       ylab = "Signed Loadings",
                       #font.size = 1
                       )  
  

grid.arrange(as.grob(loading1),
             as.grob(loading2),
             ncol = 2,nrow = 1
             )

loads_plsc <- recordPlot()

```

  Contributions and loadings are similar, but not exactly the same. Here were see that there are quite a few more variables that contribute significantly to these dimensions than for which a significant portion of the variance is explained. We do see similar groups, however: on the first dimension, the tempo variables are contributing significantly, along with some from harmony, density, genre, dynamics, motion, range, and articulation. The adjectives contributing significantly are Bright, colorful, Dancing, Fast, Happy, Light, and Valiant in the negative direction, and Dark, Dull, Long, Melancholy, Monotonous, Sad, Slow, Solemn, and Weak in the positive direction. What's notable here is that while some of these variables did contribute significantly in the plots above (see \@ref(fig:factormaps.A) and \@ref(fig:factormaps.Q)), some didn't contribute much at all and fell near the barycenter of the factor plot. We also see that this juxtaposes some negatively and positively valenced adjectives, which allows us to identify which of the musical qualities contributes to the valence dimension. 
  The second dimension tells us a similar story. Here we see more of the harmony variables, along with one tempo variable, some density, genre, a few dynamics, contour, motion, range, and articulation. The adjectives contributing negatively are Aggressive, Complex, Dense, Disturbing, Incisive, Mysterious, Powerful, Surprising, and Varied, and those contributing positively are Light, Round, Soft, Transparent, and Warm. Again we see similar effects of variables that may not have contributed significantly to their respective plots above, but are contributing significantly here. Also, this second latent variable seems to be defining the arousal dimension.  
```{r contsplsc, fig.width = 8, fig.height = 6, fig.show='hold', message=F}

ctri <- pls.res$TExPosition.Data$ci*sign(pls.res$TExPosition.Data$fi)
ctrj <- pls.res$TExPosition.Data$cj * sign(pls.res$TExPosition.Data$fj)

conts.sigonly <- barplot.sigonly(x = ctri,
                                 y = ctrj,
                                 th = "mean",
                                 type = "cont")


contribution1 <- PrettyBarPlot2(bootratio = conts.sigonly$data$Dim1, 
                       threshold = conts.sigonly$t.hold$thr.tog, 
                       ylim = conts.sigonly$data$y.limits$ylims.tog$Dim1,
                       color4bar = c(conts.sigonly$color$x.vec$Dim1, conts.sigonly$color$y.vec$Dim1),
                       color4ns = "gray75", 
                       plotnames = TRUE, 
                       main = 'Contributions to the First Latent Variables', 
                       ylab = "Signed Contributions"
                       #font.size = 1
                       )
  
contribution2 <- PrettyBarPlot2(bootratio = conts.sigonly$data$Dim2, 
                       threshold = conts.sigonly$t.hold$thr.tog, 
                       ylim =conts.sigonly$data$y.limits$ylims.tog$Dim2,
                       color4bar = c(conts.sigonly$color$x.vec$Dim2, conts.sigonly$color$y.vec$Dim2),
                       color4ns = "gray75", 
                       plotnames = TRUE, 
                       main = 'Contributions to the Second Latent Variables', 
                       ylab = "Signed Contributions",
                       #font.size = 1
                       )  

grid.arrange(as.grob(contribution1),
             as.grob(contribution2),
             ncol = 1,nrow = 2
             )

contributionsplsc <- recordPlot()
```

### Discussion
The factor score plots for this analysis shows that the first two sets of latent variables extracted by the analysis effectively separate the groups of excerpts into the clusters defined in the HCA for the adjectives survey. This factor plot shows us how the strongest correlated signal between the two data tables separates Excerpts groups 2 and 3, but groups 1 and 2 didn't contribute much to this dimension, instead contributing to the 2nd latent variables. The second latent variable separates Groups 1 and 4, with Groups 2 and 3 more barycentric. This suggests that, generally speaking, the excerpts that were clustered in groups 2 and 3 are those that could be defined by positive and negative valence, respectively, and those in groups 1 and 4 would be defined more by high and low arousal. That being said, these excerpts are not defined *exclusively* along these dimensions, but rather more by one than the other. For example, excerpt 26 is characterized by being one of the most extreme examples of positive valence, but doesn't score as highly on the arousal dimension, similarly with excerpt 27 with negative valence. This is contrasted with excerpt 7, which is one of the most negatively valenced stimuli, but also scores very high on arousal, although the barycenter for that group is near the origin of that plot.

```{r factorplotsPLSC, fig.width = 12, fig.height = 6}
latvar.1 <- cbind(pls.res$TExPosition.Data$lx[,1],pls.res$TExPosition.Data$ly[,1])
colnames(latvar.1) <- c("Lx 1", "Ly 1")

zedesign <- adj.design$thedesign[-c(6,14)]
lescoleurs <- adj.design$ex.cols[-c(6,14)]
coleur4group <- adj.design$col4exgrp


# compute means
lv.1.group <- getMeans(latvar.1, zedesign)

# get bootstrap intervals of groups
lv.1.group.boot <- Boot4Mean(latvar.1, zedesign)
colnames(lv.1.group.boot$BootCube) <- c("Lx 1", "Ly 1")

#Next, we can start plotting:

plot.lv1 <- createFactorMap(latvar.1,
                         col.points = lescoleurs,
                         col.labels = lescoleurs,
                         alpha.points = 0.4, alpha.labels = 0.4,
                         text.cex = 3, title = "Latent Variable Plot 1"
                         )

plot1.mean <- createFactorMap(lv.1.group,
                              col.points = coleur4group,
                              col.labels = coleur4group,
                              cex = 4,
                              pch = 17,
                              alpha.points = 0.8, 
                              text.cex = 6)

plot1.meanCI <- MakeCIEllipses(lv.1.group.boot$BootCube[,c(1:2),], # get the first two components
                              col = adj.design$col4exgrp,
                              names.of.factors = c("Lx 1", "Ly 1")
                              )

plot1 <- plot.lv1$zeMap_background + plot.lv1$zeMap_dots + plot.lv1$zeMap_text +
           plot1.mean$zeMap_text + plot1.meanCI


latvar.2 <- cbind(pls.res$TExPosition.Data$lx[,2],pls.res$TExPosition.Data$ly[,2])
colnames(latvar.2) <- c("Lx 2", "Ly 2")

# compute means
lv.2.group <- getMeans(latvar.2, zedesign)

# get bootstrap intervals of groups
lv.2.group.boot <- Boot4Mean(latvar.2, zedesign)
colnames(lv.2.group.boot$BootCube) <- c("Lx 2", "Ly 2")

#Next, we can start plotting:

plot.lv2 <- createFactorMap(latvar.2,
                         col.points = lescoleurs,
                         col.labels = lescoleurs,
                         alpha.points = 0.4, alpha.labels = 0.4,
                         text.cex = 3, title = "Latent Variable Plot 2"
                         )

plot2.mean <- createFactorMap(lv.2.group,
                              col.points = coleur4group,
                              col.labels = coleur4group,
                              cex = 4,
                              pch = 17,
                              alpha.points = 0.8, 
                              text.cex = 6)

plot2.meanCI <- MakeCIEllipses(lv.2.group.boot$BootCube[,c(1:2),], # get the first two components
                              col = coleur4group,
                              names.of.factors = c("Lx 2", "Ly 2")
                              )

plot2 <- plot.lv2$zeMap_background + plot.lv2$zeMap_dots + plot.lv2$zeMap_text +
           plot2.mean$zeMap_text + plot2.meanCI


grid.arrange(as.grob(plot1),
             as.grob(plot2),
             ncol = 2,nrow = 1
             )
plsc.fplot <- recordPlot()
```


# General Discussion

  Although this study was designed to evaluate the sensory or cognitive response to music, and not specifically the emotional response, there is significant overlap in the results observed here and the results of the work investigating music and emotion. The appearance of the valence-arousal plane in the results of experiment 2 was not unexpected, even though the adjectives we selected were not intended to be explicitly emotional. This goes to show difficult it is to avoid any emotional content when selecting descriptors, and from another perspective, how much emotional contagion the musical examples carry. Overall, this supports the idea that the first two dimensions on which music is judged holistically are valence and arousal. 
  Some of the results discussed in Experiment 1 require more explanation. In experiment 1, there was an issue of having two individual excerpts dominate the factor space, numbers 6 and 14, which did not happen in experiment 2. One of the ways in which CA is different from PCA is that PCA is usually unweighted. CA, on the other hand, makes use of weights and masses to find the average observation. Information that is common, therefore, falls towards the center of the plot, while information that is further from the average, in other words, more rare, ends up further from the center of the factor plots. [cite] Therefore, if a survey like the one used in experiment 1 includes a item that is wildly different than the others in the set, the ratings will be very different, and that item will dominate the factor space. In this case we have two such examples: excerpts 6 and 14. Excerpt 6 was written as a Steve-Reich-esque minimalist, ostinato based excerpt, and excerpt 14 was written to be jazzy. The reason this effect occurs with the first survey and not the second is that the musical qualities on which the excerpts were rated were explicit and designed to separate the excerpts along the various musical dimensions, while the adjectives survey was designed to evaluate the excerpts more generally on holistic qualities. Excerpt 6 still appears as a minor outlier in the visualizations for the second survey, but does not dominate the space the way it does in the results of the first.
  What we did to mitigate that is to use those two excerpts as *supplementary projections*, sometimes also referred to as *out of sample observations*. This allows us to evaluate what information is shared by those outliers with the other elements in the dataset without having them dominate the visualization of the factor space. If, when we projected those values into the factor space, they projected onto the origin or very close to it, we would know that those observations shared no information with the other variables. The fact that they are where they are offers support to the idea that the first survey separates the excerpts approximately by genre. Because the 'genre' information isn't shared with the other observations, they are being projected onto the space sharing only the information that does not deal with genre, like tempo or range. What this tells us is that musical qualities surveys captured a result that may have characterized by 4-6 factors, each approximating genre and the qualities associated with that genre and the general affective space captured an entirely different set of information about the stimuli and the perception of the stimuli.  
  The hierarchical cluster analyses revealed different groupings in how the stimuli were rated between the two surveys. The PLSC then showed that when including both sets of data, there was a coherent interpretable factor space on which the excerpts were plotted. There are a number of ways to further disambiguate the results of the surveys. One way would be to run a MFA, similar to the one above that plotted the difference between French and American raters on the adjective survey. This would allow for a number of different interpretations. Firstly, it would calculate the overall factor space for the excerpts, including all of the data from both surveys, without separating out the first and second dimensions to plot them separately. It would also identify the specific partial factor scores for each of the data tables within that factor space that would allow for the interpretation of the relative differences between the data tables. The drawback to both of these, however, is that unlike the separate correspondence analyses we ran above, where the row and column scores can be plotted in the same space, neither MFA nor the PLSC allow for that type of visualization. That being said, because different types of analysis reveal different aspects of the data, running both analyses can provide a broader understanding of the data, and each could provide explanations for what remains ambiguous in the other.
  An important overall takeaway from this is that with a deep general understanding of the stimuli, we may be able to predict the approximate dimensionality of the solution factor space. In the first survey, the solution was that the stimuli were largely separated along genre or stylistic lines. One issue that arose with this is that there was only one example of minimalist and jazz music. To have a solution in which we didn't see these specific excerpts as outliers, but as coherent members of a factor space, we would need more examples of those styles. This suggests that when creating surveys or designing stimuli, we should keep in mind that we need multiple items per group, or presumed dimension. This is not to say that we will always be able to a priori predict the factor space of the solution. For example, experiment 2 may also have benefitted from more minimalist or jazz examples - in a system in which the overall structure is obtained by evaluating the stimuli holistically, having a single outlier will necessarily distort the space. Either because it is an outlier in sensory terms or because it is the only stimulus against which there is no direct reference. This in a way embodies the issue described in the introduction, where we have a single dimension that is noisy. This really only applies to experiment 2. The noise comes from the fact that participants were likely to be less familiar with mimalism and/or jazz than the trained musicians who took the QS, but the reason the results are overall robust to that noise is that the participants were not asked to rate the excerpts on any explicit dimensions or qualities. 

## Limitations & future directions

 Although we evaluate the scores and ratings of participants from different countries, we recognize that the issue of multiculturality is not addressed to a significant degree in this study. The sample was still largely students, and France and the United States share similar musical cultures. To truly address this question, it would be very interesting to include participants from multiple, contrasting musical cultures, with languages that are more distinct than English and French. This presents new problems, however, as the specific musical qualities included in the surveys may not all apply to or translate well to other musical cultures. Harmony, for example, is a concept that is developed to a significant degree in western music, but melody or rhythm may be the fundamental focus of other musical cultures (cite patel here? I forget.). 
 Another question that fell beyond the scope of this study is the concept of semantic drift between languages. Although illustrated in \@ref(fig:mfasbs), the source of the differences between French and American participants is not entirely clear. We humbly hazard to guess that some of the sources of the difference include aspects of perception that extend beyond the musical. These could be linguistic sources, such as the physical characteristics of the words themselves, the cultural associations with the words, or the frequency of use in either language. Diving more into those questions of linguistics and semantic drift between languages would be a fascinating future study.
 Another interesting study would be to repeat this study using adjectives from specific domains or that that avoid explicit emotional or musical content, to see how music maps onto different sensory spaces. For example, 'moist', 'slimy', 'dry', 'puckered', 'smooth'. Although some of these adjectives may carry musical weight, in the context of other words that all relate to haptic sensation, it may provide some interesting feedback regarding how the music maps into other sensory domains.
 Finally, using these studies may provide pilot work for the way in which people without language react to music, nonverbal autistic people, for example. Whereas this study explicitly uses language as an interlocutor for music perception, it offers insight into ways to better communicate with people who do not have that ability.

# Conclusions
  By developing investigative paradigms that are accessible on mobile platforms and that reduce participant demand while maintaining rigor and integrity, we are likely to be able to reach a much greater subset of the population. If we are able to pair this kind of data gathering with appropriate analysis, we can maintain the standards of scientific integrity that we as a community expect with traditional hypothesis testing. The literature to date in the music cognition domain has focused on a fairly small subset of the multivariate analyses available to investigate these questions. As presented here, the number of ways that exist to analyze the data from a single set of experiments is considerable, and the results of each analysis illuminate different parts of the story the data are telling. Not every form of analysis is appropriate in every context, but understanding how, and perhaps more importantly when, to apply a technique or type of analysis is an important to uncovering new perspectives or insights.
  
```{r saveGraphs, message = FALSE, warning = FALSE, error = FALSE}
powerpointFilename <- 'Music-Descriptor-Space.pptx'
path2pptx    <- './Analysis/'
name4Graphs  <- paste0(path2pptx,powerpointFilename)
title4Graphs <- 'Music Descriptor Space '



pptx4musdim <- PTCA4CATA::saveGraph2pptx(file2Save.pptx = name4Graphs, 
                 title = title4Graphs, 
                 addGraphNames = TRUE)
```

\newpage

# References

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id="refs" custom-style="Bibliography"></div>
\endgroup
